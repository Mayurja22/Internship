{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34830af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time \n",
    "import urllib.request\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402348a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca8a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b716503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ba0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "video = []\n",
    "\n",
    "tables = driver.find_elements(By.XPATH, \"//table[@class='sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter']\")\n",
    "\n",
    "if tables:\n",
    "    table = tables[0]  \n",
    "\n",
    "    tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "    rows = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "        if len(cells) >= 4:  \n",
    "            try:\n",
    "                video_name = cells[0].find_element(By.TAG_NAME, 'a').text\n",
    "            except NoSuchElementException:\n",
    "                video_name = \"N/A\"  \n",
    "            try:\n",
    "                uploader = cells[1].find_element(By.TAG_NAME, 'a').text\n",
    "            except NoSuchElementException:\n",
    "                uploader = \"N/A\"  \n",
    "\n",
    "            views = cells[2].text\n",
    "            date = cells[3].text\n",
    "\n",
    "            video.append({\n",
    "                'Video Name': video_name,\n",
    "                'Uploader': uploader,\n",
    "                'Views': views,\n",
    "                'Date': date\n",
    "            })\n",
    "\n",
    "else:\n",
    "    print(\"No tables found with the given XPath.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5519e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Video Name                                 Uploader                                     Views  Date              \n",
      "0                            Baby Shark Dance  Pinkfong Baby Shark - Kids' Songs & Stories  15.09      June 17, 2016\n",
      "1                                   Despacito                                   Luis Fonsi   8.54   January 12, 2017\n",
      "2                        Johny Johny Yes Papa                                          N/A   6.95    October 8, 2016\n",
      "3                                   Bath Song                   Cocomelon - Nursery Rhymes   6.85        May 2, 2018\n",
      "4                           Wheels on the Bus                   Cocomelon - Nursery Rhymes   6.56       May 24, 2018\n",
      "5                               See You Again                                  Wiz Khalifa   6.40      April 6, 2015\n",
      "6                                Shape of You                                   Ed Sheeran   6.33   January 30, 2017\n",
      "7                 Phonics Song with Two Words        ChuChu TV Nursery Rhymes & Kids Songs   6.00      March 6, 2014\n",
      "8                                 Uptown Funk                                  Mark Ronson   5.33  November 19, 2014\n",
      "9                               Gangnam Style                                          Psy   5.29      July 15, 2012\n",
      "10  Learning Colors â€“ Colorful Eggs on a Farm                                          N/A   5.15  February 27, 2018\n",
      "11                             Dame Tu Cosita                                Ultra Records   4.74      April 5, 2018\n",
      "12                                     Axel F                                   Crazy Frog   4.69      June 16, 2009\n",
      "13                         Masha and the Bear                                   Get Movies   4.60   January 31, 2012\n",
      "14                        Baa Baa Black Sheep                   Cocomelon - Nursery Rhymes   4.17      June 25, 2018\n",
      "15                             Lakdi Ki Kathi                                          N/A   4.13      June 14, 2018\n",
      "16                                      Sugar                                     Maroon 5   4.09   January 14, 2015\n",
      "17                             Counting Stars                                  OneRepublic   4.05       May 31, 2013\n",
      "18                                       Roar                                   Katy Perry   4.03  September 5, 2013\n",
      "19           Waka Waka (This Time for Africa)                                      Shakira   4.01       June 4, 2010\n",
      "20                      Shree Hanuman Chalisa                        T-Series Bhakti Sagar   3.97       May 10, 2011\n",
      "21          Humpty the train on a fruits ride                                          N/A   3.89   January 26, 2018\n",
      "22                                      Sorry                                Justin Bieber   3.84   October 22, 2015\n",
      "23                          Thinking Out Loud                                   Ed Sheeran   3.79    October 7, 2014\n",
      "24                                    Perfect                                   Ed Sheeran   3.78   November 9, 2017\n",
      "25                                 Dark Horse                                   Katy Perry   3.77  February 20, 2014\n",
      "26                                 Let Her Go                                    Passenger   3.70      July 25, 2012\n",
      "27                                      Faded                                  Alan Walker   3.67   December 3, 2015\n",
      "28                             Girls Like You                                     Maroon 5   3.65       May 31, 2018\n",
      "29                                    Lean On                         Major Lazer Official   3.65     March 22, 2015\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)        \n",
    "pd.set_option('display.colheader_justify', 'left') \n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  \n",
    "\n",
    "df = pd.DataFrame(video)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137d45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8253f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f93a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5eab219",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c85af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element(By.XPATH,\"/html/body/header/div[3]/div[2]/ul/div[1]/a[2]\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f0a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element(By.XPATH,\"/html/body/section/div/div/div/div/div/div[2]/div[2]/div[1]/div[2]\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c689d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = driver.find_elements(By.XPATH, \"//div[@class='tab-inner-content']\")\n",
    "\n",
    "fixture_list = []\n",
    "\n",
    "for match in matches:\n",
    "    series_list = match.find_elements(By.XPATH, \".//div[@class='match-info']/h5\")\n",
    "    place_list = match.find_elements(By.XPATH, \".//div[@class='match-info']/div[3]\")\n",
    "    date_list = match.find_elements(By.XPATH, \".//div[@class='match-date-info']/div[1]\")\n",
    "    time_list = match.find_elements(By.XPATH, \".//div[@class='match-date-info']/div[2]\")\n",
    "\n",
    "    for i in range(len(series_list)):\n",
    "        series = series_list[i].text\n",
    "        place = place_list[i].text\n",
    "        date = date_list[i].text\n",
    "        time_match = time_list[i].text\n",
    "\n",
    "        fixture_list.append([series, place, date, time_match])\n",
    "\n",
    "df = pd.DataFrame(fixture_list, columns=[\"Series\", \"Place\", \"Date\", \"Time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d88121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 Oct</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bangladesh Tour of India T20 Series 2024</td>\n",
       "      <td>Shrimant Madhavrao Scindia Cricket Stadium, Gw...</td>\n",
       "      <td>6 Oct</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC Womens T20 World Cup 2024</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 Oct</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia U19 Tour of India Multiday Series</td>\n",
       "      <td>M A Chidambaram Stadium, Chennai</td>\n",
       "      <td>7 Oct</td>\n",
       "      <td>9:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh Tour of India T20 Series 2024</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>9 Oct</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Series  \\\n",
       "0                ICC Womens T20 World Cup 2024   \n",
       "1     Bangladesh Tour of India T20 Series 2024   \n",
       "2                ICC Womens T20 World Cup 2024   \n",
       "3  Australia U19 Tour of India Multiday Series   \n",
       "4     Bangladesh Tour of India T20 Series 2024   \n",
       "\n",
       "                                               Place   Date       Time  \n",
       "0         Dubai International Cricket Stadium, Dubai  4 Oct  19:30 IST  \n",
       "1  Shrimant Madhavrao Scindia Cricket Stadium, Gw...  6 Oct  19:00 IST  \n",
       "2         Dubai International Cricket Stadium, Dubai  6 Oct  15:30 IST  \n",
       "3                   M A Chidambaram Stadium, Chennai  7 Oct   9:30 IST  \n",
       "4                        Arun Jaitley Stadium, Delhi  9 Oct  19:00 IST  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a43e361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc53385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53816aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://statisticstimes.com/#google_vignette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c9a1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9980ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(23-24) GSDP(22-23) GSDP(21-22)  \\\n",
      "0     1                Maharashtra           -           -   3,108,022   \n",
      "1     2                 Tamil Nadu   2,700,109   2,364,514   2,071,286   \n",
      "2     3                  Karnataka   2,500,733   2,269,995   1,978,094   \n",
      "3     4              Uttar Pradesh   2,547,861   2,258,040   1,975,595   \n",
      "4     5                    Gujarat           -   2,230,609   1,928,683   \n",
      "5     6                West Bengal   1,700,939   1,531,758   1,329,238   \n",
      "6     7                  Rajasthan   1,524,030   1,365,849   1,193,489   \n",
      "7     8             Andhra Pradesh   1,439,674   1,303,524   1,148,471   \n",
      "8     9                  Telangana   1,463,960   1,308,034   1,124,204   \n",
      "9    10             Madhya Pradesh   1,363,327   1,246,471   1,092,964   \n",
      "10   11                     Kerala           -   1,046,188     934,542   \n",
      "11   12                      Delhi   1,107,746   1,014,688     881,336   \n",
      "12   13                    Haryana   1,095,535     984,055     868,905   \n",
      "13   14                     Odisha     832,790     753,177     662,886   \n",
      "14   15                      Bihar           -     751,396     650,302   \n",
      "15   16                     Punjab     736,423     676,164     617,192   \n",
      "16   17                      Assam     565,401     493,167     411,454   \n",
      "17   18               Chhattisgarh     505,887     464,399     410,525   \n",
      "18   19                  Jharkhand           -     393,722     358,863   \n",
      "19   20                Uttarakhand     346,206     303,781     267,143   \n",
      "20   21            Jammu & Kashmir     246,465     224,226     193,352   \n",
      "21   22           Himachal Pradesh     207,430     191,728     172,162   \n",
      "22   23                        Goa           -      93,672      84,266   \n",
      "23   24                    Tripura           -      72,636      62,550   \n",
      "24   25                 Chandigarh           -      54,285      46,096   \n",
      "25   26                 Puducherry           -      49,643      43,810   \n",
      "26   27                  Meghalaya      47,381      42,697      38,785   \n",
      "27   28                     Sikkim           -      42,756      37,557   \n",
      "28   29                    Manipur           -           -      36,594   \n",
      "29   30          Arunachal Pradesh           -      39,630      34,775   \n",
      "30   31                   Nagaland           -      35,643      31,038   \n",
      "31   32                    Mizoram           -           -      27,824   \n",
      "32   33  Andaman & Nicobar Islands           -           -      10,371   \n",
      "\n",
      "   Share(18-19) GDP($ billion)  \n",
      "0     3,108,022         13.17%  \n",
      "1     2,071,286          8.78%  \n",
      "2     1,978,094          8.38%  \n",
      "3     1,975,595          8.37%  \n",
      "4     1,928,683          8.17%  \n",
      "5     1,329,238          5.63%  \n",
      "6     1,193,489          5.06%  \n",
      "7     1,148,471          4.87%  \n",
      "8     1,124,204          4.76%  \n",
      "9     1,092,964          4.63%  \n",
      "10      934,542          3.96%  \n",
      "11      881,336          3.73%  \n",
      "12      868,905          3.68%  \n",
      "13      662,886          2.81%  \n",
      "14      650,302          2.76%  \n",
      "15      617,192          2.62%  \n",
      "16      411,454          1.74%  \n",
      "17      410,525          1.74%  \n",
      "18      358,863          1.52%  \n",
      "19      267,143          1.13%  \n",
      "20      193,352          0.82%  \n",
      "21      172,162          0.73%  \n",
      "22       84,266          0.36%  \n",
      "23       62,550          0.27%  \n",
      "24       46,096          0.20%  \n",
      "25       43,810          0.19%  \n",
      "26       38,785          0.16%  \n",
      "27       37,557          0.16%  \n",
      "28       36,594          0.16%  \n",
      "29       34,775          0.15%  \n",
      "30       31,038          0.13%  \n",
      "31       27,824          0.12%  \n",
      "32       10,371          0.04%  \n"
     ]
    }
   ],
   "source": [
    "economy_button = driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy_button.click()\n",
    "button=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "button.click()\n",
    "\n",
    "india_economy_link = driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "india_economy_link.click()\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "\n",
    "gdp_data = []\n",
    "\n",
    "tables = driver.find_elements(By.XPATH, \"(//div[@class='dataTables_wrapper']//table)[1]\")\n",
    "\n",
    "if tables:\n",
    "    table = tables[0]  \n",
    "\n",
    "    tbody = table.find_element(By.TAG_NAME, 'tbody')\n",
    "    rows = tbody.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "\n",
    "        if len(cells) >= 7:  \n",
    "            try:\n",
    "                rank = cells[0].text\n",
    "            except NoSuchElementException:\n",
    "                rank = \"N/A\"\n",
    "                \n",
    "            try:\n",
    "                state = cells[1].text\n",
    "            except NoSuchElementException:\n",
    "                state = \"N/A\"\n",
    "                \n",
    "            try:\n",
    "                gsdp_23_24 = cells[2].text if cells[2].text != \"_\" else \"N/A\"\n",
    "            except NoSuchElementException:\n",
    "                gsdp_23_24 = \"N/A\"\n",
    "                \n",
    "            try:\n",
    "                gsdp_22_23 = cells[3].text if cells[3].text != \"_\" else \"N/A\"\n",
    "            except NoSuchElementException:\n",
    "                gsdp_22_23 = \"N/A\"\n",
    "                \n",
    "            try:\n",
    "                gsdp_21_22 = cells[4].text if cells[4].text != \"_\" else \"N/A\"\n",
    "            except NoSuchElementException:\n",
    "                share_21_22 = \"N/A\"\n",
    "            try:\n",
    "                share_21_22 = cells[4].text if cells[4].text != \"_\" else \"N/A\"\n",
    "            except NoSuchElementException:\n",
    "                share_21_22 = \"N/A\"\n",
    "                \n",
    "            try:\n",
    "                gdp_billion = cells[5].text if cells[5].text != \"_\" else \"N/A\"\n",
    "            except NoSuchElementException:\n",
    "                gdp_billion = \"N/A\"\n",
    "\n",
    "        \n",
    "            gdp_data.append({\n",
    "                'Rank': rank,\n",
    "                'State': state,\n",
    "                'GSDP(23-24)': gsdp_23_24,\n",
    "                'GSDP(22-23)': gsdp_22_23,\n",
    "                'GSDP(21-22)': gsdp_21_22,\n",
    "                'Share(18-19)': share_21_22,\n",
    "                'GDP($ billion)': gdp_billion\n",
    "            })\n",
    "\n",
    "else:\n",
    "    print(\"No tables found with the given XPath.\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(gdp_data)\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac568a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ad4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68791126",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb8427b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_menu = driver.find_element(By.XPATH, \"/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a\")\n",
    "charts_menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "810d7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Song Name                          Artist Name Last Week Rank  \\\n",
      "0   A Bar Song (Tipsy)                            Shaboozey              1   \n",
      "1      I Had Some Help  Post Malone Featuring Morgan Wallen              2   \n",
      "2             Espresso                    Sabrina Carpenter              3   \n",
      "3     Good Luck, Babe!                        Chappell Roan              4   \n",
      "4     Die With A Smile               Lady Gaga & Bruno Mars              5   \n",
      "..                 ...                                  ...            ...   \n",
      "95          Diet Pepsi                          Addison Rae             81   \n",
      "96         Coincidence                    Sabrina Carpenter             73   \n",
      "97     Passport Junkie                             Rod Wave             61   \n",
      "98    Circadian Rhythm                                Drake             66   \n",
      "99       Sharpest Tool                    Sabrina Carpenter             76   \n",
      "\n",
      "   Peak Rank Weeks on Chart  \n",
      "0          1             24  \n",
      "1          1             20  \n",
      "2          3             24  \n",
      "3          4             25  \n",
      "4          3              6  \n",
      "..       ...            ...  \n",
      "95        81              3  \n",
      "96        26              5  \n",
      "97        61              2  \n",
      "98        59              4  \n",
      "99        21              5  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "songs_data = []\n",
    "\n",
    "\n",
    "songs = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='o-chart-results-list-row-container']\"))\n",
    ")\n",
    "\n",
    "\n",
    "for song in songs:\n",
    "    try:\n",
    "       \n",
    "        song_name = song.find_element(By.XPATH, \".//ul/li[4]/ul/li[1]/h3\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        song_name = \"N/A\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        artist_name = song.find_element(By.XPATH, \".//ul/li[4]/ul/li[1]/span\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        artist_name = \"N/A\"\n",
    "\n",
    "    try:\n",
    "       \n",
    "        last_week_rank = song.find_element(By.XPATH, \".//ul/li[4]/ul/li[4]/span\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        last_week_rank = \"N/A\"\n",
    "\n",
    "    try:\n",
    "  \n",
    "        peak_rank = song.find_element(By.XPATH, \".//ul/li[4]/ul/li[5]/span\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        peak_rank = \"N/A\"\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        weeks_on_board = song.find_element(By.XPATH, \".//ul/li[4]/ul/li[6]/span\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        weeks_on_board = \"N/A\"\n",
    "\n",
    "    \n",
    "    songs_data.append({\n",
    "        'Song Name': song_name,\n",
    "        'Artist Name': artist_name,\n",
    "        'Last Week Rank': last_week_rank,\n",
    "        'Peak Rank': peak_rank,\n",
    "        'Weeks on Chart': weeks_on_board\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(songs_data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415b8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e098089",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4995b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ebb517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book Name       Author Name  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes Sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "books_data = []\n",
    "\n",
    "\n",
    "table = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//div[@class='embed block']//table[@class='in-article sortable']\"))\n",
    ")\n",
    "rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "\n",
    "    columns = row.find_elements(By.TAG_NAME, 'td')\n",
    "    \n",
    "    if len(columns) >= 6:  \n",
    "        book_name = columns[1].text.strip()    \n",
    "        author_name = columns[2].text.strip()  \n",
    "        volumes_sold = columns[3].text.strip()  \n",
    "        publisher = columns[4].text.strip()     \n",
    "        genre = columns[5].text.strip()         \n",
    "\n",
    "        # Append data to list\n",
    "        books_data.append({\n",
    "            'Book Name': book_name,\n",
    "            'Author Name': author_name,\n",
    "            'Volumes Sold': volumes_sold,\n",
    "            'Publisher': publisher,\n",
    "            'Genre': genre\n",
    "        })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(books_data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDb\n",
    "#404 Error\n",
    "#Someday we'll find it... the website connection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaa1c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45575365",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bacda176",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f54d9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/main/div/div[2]/section[1]/div[2]/a\")\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84875c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select/option[5]\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23d93415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Dataset Name Data Type  \\\n",
      "0                                                Iris             \n",
      "1                                       Heart Disease             \n",
      "2                                        Wine Quality             \n",
      "3                                               Adult             \n",
      "4                Breast Cancer Wisconsin (Diagnostic)             \n",
      "5                                      Bank Marketing             \n",
      "6                                                Wine             \n",
      "7                                 Student Performance             \n",
      "8                                       Online Retail             \n",
      "9                                      Car Evaluation             \n",
      "10                                           Diabetes             \n",
      "11     Predict Students' Dropout and Academic Success             \n",
      "12                                         Automobile             \n",
      "13                                            Abalone             \n",
      "14                                           Mushroom             \n",
      "15                                        Air Quality             \n",
      "16                                           Dry Bean             \n",
      "17                       Statlog (German Credit Data)             \n",
      "18       Human Activity Recognition Using Smartphones             \n",
      "19                     Default of Credit Card Clients             \n",
      "20  Estimation of Obesity Levels Based On Eating H...             \n",
      "21                                           Auto MPG             \n",
      "22                                       Bike Sharing             \n",
      "23                                           Spambase             \n",
      "24                                   Online Retail II             \n",
      "\n",
      "                                                 Task  \\\n",
      "0   A small classic dataset from Fisher, 1936. One...   \n",
      "1   4 databases: Cleveland, Hungary, Switzerland, ...   \n",
      "2   Two datasets are included, related to red and ...   \n",
      "3   Predict whether annual income of an individual...   \n",
      "4        Diagnostic Wisconsin Breast Cancer Database.   \n",
      "5   The data is related with direct marketing camp...   \n",
      "6   Using chemical analysis to determine the origi...   \n",
      "7   Predict student performance in secondary educa...   \n",
      "8   This is a transnational data set which contain...   \n",
      "9   Derived from simple hierarchical decision mode...   \n",
      "10              This diabetes dataset is from AIM '94   \n",
      "11  A dataset created from a higher education inst...   \n",
      "12               From 1985 Ward's Automotive Yearbook   \n",
      "13  Predict the age of abalone from physical measu...   \n",
      "14  From Audobon Society Field Guide; mushrooms de...   \n",
      "15  Contains the responses of a gas multisensor de...   \n",
      "16  Images of 13,611 grains of 7 different registe...   \n",
      "17  This dataset classifies people described by a ...   \n",
      "18  Human Activity Recognition database built from...   \n",
      "19  This research aimed at the case of customers' ...   \n",
      "20  This dataset include data for the estimation o...   \n",
      "21  Revised from CMU StatLib library, data concern...   \n",
      "22  This dataset contains the hourly and daily cou...   \n",
      "23              Classifying Email as Spam or Non-Spam   \n",
      "24  A real online retail transaction data set of t...   \n",
      "\n",
      "                            Attribute Type  \\\n",
      "0                           Classification   \n",
      "1                           Classification   \n",
      "2               Classification, Regression   \n",
      "3                           Classification   \n",
      "4                           Classification   \n",
      "5                           Classification   \n",
      "6                           Classification   \n",
      "7               Classification, Regression   \n",
      "8               Classification, Clustering   \n",
      "9                           Classification   \n",
      "10                          Classification   \n",
      "11                          Classification   \n",
      "12                              Regression   \n",
      "13              Classification, Regression   \n",
      "14                          Classification   \n",
      "15                              Regression   \n",
      "16                          Classification   \n",
      "17                          Classification   \n",
      "18              Classification, Clustering   \n",
      "19                          Classification   \n",
      "20  Classification, Regression, Clustering   \n",
      "21                              Regression   \n",
      "22                              Regression   \n",
      "23                          Classification   \n",
      "24  Classification, Regression, Clustering   \n",
      "\n",
      "                               No. of Instances No. of Features Year  \n",
      "0                                       Tabular                  N/A  \n",
      "1                                  Multivariate                  N/A  \n",
      "2                                  Multivariate                  N/A  \n",
      "3                                  Multivariate                  N/A  \n",
      "4                                  Multivariate                  N/A  \n",
      "5                                  Multivariate                  N/A  \n",
      "6                                       Tabular                  N/A  \n",
      "7                                  Multivariate                  N/A  \n",
      "8         Multivariate, Sequential, Time-Series                  N/A  \n",
      "9                                  Multivariate                  N/A  \n",
      "10                    Multivariate, Time-Series                  N/A  \n",
      "11                                      Tabular                  N/A  \n",
      "12                                 Multivariate                  N/A  \n",
      "13                                      Tabular                  N/A  \n",
      "14                                 Multivariate                  N/A  \n",
      "15                    Multivariate, Time-Series                  N/A  \n",
      "16                                 Multivariate                  N/A  \n",
      "17                                 Multivariate                  N/A  \n",
      "18                    Multivariate, Time-Series                  N/A  \n",
      "19                                 Multivariate                  N/A  \n",
      "20                                 Multivariate                  N/A  \n",
      "21                                 Multivariate                  N/A  \n",
      "22                                 Multivariate                  N/A  \n",
      "23                                 Multivariate                  N/A  \n",
      "24  Multivariate, Sequential, Time-Series, Text                  N/A  \n"
     ]
    }
   ],
   "source": [
    "datasets_data = []\n",
    "\n",
    "dataset_containers = driver.find_elements(By.XPATH, \"//div[@class='flex flex-col gap-1']/div[@role='row']\")\n",
    "\n",
    "for container in dataset_containers:\n",
    "    try:\n",
    "        # Dataset Name\n",
    "        dataset_name = container.find_element(By.XPATH, \".//div[@class='relative col-span-8 sm:col-span-7']/h2/a\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        dataset_name = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        # Task\n",
    "        task = container.find_element(By.XPATH, \".//div[@class='relative col-span-8 sm:col-span-7']/p[@class='truncate mr-8']\").text.strip()\n",
    "    except NoSuchElementException:\n",
    "        task = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        # Attribute type, Data type, No. of instances, No. of features\n",
    "        details_div = container.find_element(By.XPATH, \".//div[@class='my-2 hidden gap-4 md:grid grid-cols-12']\")\n",
    "        attribute_type = details_div.find_elements(By.TAG_NAME, 'div')[0].text.strip()\n",
    "        data_type = details_div.find_elements(By.TAG_NAME, 'div')[1].text.strip()\n",
    "        num_instances = details_div.find_elements(By.TAG_NAME, 'div')[2].text.strip()\n",
    "        num_features = details_div.find_elements(By.TAG_NAME, 'div')[3].text.strip()\n",
    "    except NoSuchElementException:\n",
    "        attribute_type = data_type = num_instances = num_features = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        # Click the dropdown button for the year\n",
    "        dropdown_button = container.find_element(By.XPATH, \".//svg[@class='absolute right-1 top-1/2 size-6 -translate-y-1/2 fill-primary size-5 transition-transform']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", dropdown_button)\n",
    "\n",
    "        # Wait for the table row to load and extract the year\n",
    "        table_row = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \".//div[@style]//table/tbody/tr\"))\n",
    "        )\n",
    "        date = table_row.find_elements(By.TAG_NAME, 'td')[2].text.strip()\n",
    "        year = date.split('/')[-1]\n",
    "    except NoSuchElementException:\n",
    "        year = \"N/A\"\n",
    "\n",
    "    # Append the scraped data to the list\n",
    "    datasets_data.append({\n",
    "        'Dataset Name': dataset_name,\n",
    "        'Data Type': data_type,\n",
    "        'Task': task,\n",
    "        'Attribute Type': attribute_type,\n",
    "        'No. of Instances': num_instances,\n",
    "        'No. of Features': num_features,\n",
    "        'Year': year\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(datasets_data)\n",
    "\n",
    "# Print the DataFrame to verify\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fe6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
